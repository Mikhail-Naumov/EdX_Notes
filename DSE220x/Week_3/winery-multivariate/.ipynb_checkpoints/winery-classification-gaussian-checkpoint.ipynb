{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the multivariate Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we return to winery classification, using the full set of 13 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T18:06:53.992785Z",
     "start_time": "2019-03-27T18:06:46.818520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T18:06:54.044330Z",
     "start_time": "2019-03-27T18:06:53.999833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that fits a Gaussian generative model to the data.\n",
    "For each class (`j=1,2,3`), we have:\n",
    "* `pi[j]`: the class weight\n",
    "* `mu[j,:]`: the mean, a 13-dimensional vector\n",
    "* `sigma[j,:,:]`: the 13x13 covariance matrix\n",
    "\n",
    "This means that `pi` is a 4x1 array (Python arrays are indexed starting at zero, and we aren't using `j=0`), `mu` is a 4x13 array and `sigma` is a 4x13x13 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T18:06:54.077193Z",
     "start_time": "2019-03-27T18:06:54.045920Z"
    }
   },
   "outputs": [],
   "source": [
    "c = 1000\n",
    "x = trainx\n",
    "y = trainy\n",
    "\n",
    "\n",
    "k = len(set(trainy)) #number of labels in y\n",
    "\n",
    "d = (x.shape)[1]  # number of features\n",
    "mu = np.zeros((k,d))\n",
    "sigma = np.zeros((k,d,d))\n",
    "pi = np.zeros(k)\n",
    "for label in range(1,k+1):\n",
    "    indices = (y == label)\n",
    "\n",
    "    mu[label-1] = np.mean(x[indices,:],axis=0)\n",
    "    sigma[label-1] = np.cov(x[indices,:], rowvar=0, bias=1)\n",
    "\n",
    "    sigma[label-1] = sigma[label-1] + np.identity(d) * c #treating singularity\n",
    "\n",
    "    pi[label-1] = float(sum(indices))/float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T18:06:54.088954Z",
     "start_time": "2019-03-27T18:06:54.079470Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y,c=10000):\n",
    "    #k = 3  # labels 1,2,...,k\n",
    "    k = len(set(trainy)) #number of labels in y\n",
    "    \n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y == label)\n",
    "        mu[label-1] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label-1] = np.cov(x[indices,:], rowvar=0, bias=1)\n",
    "        \n",
    "        sigma[label-1] = sigma[label-1] + np.identity(d) * c #treating singularity\n",
    "\n",
    "        pi[label-1] = float(sum(indices))/float(len(y))\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:07:12.826616Z",
     "start_time": "2019-03-27T19:07:12.819427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit a Gaussian generative model to the training data\n",
    "mu, sigma, pi = fit_generative_model(trainx,trainy,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use the model to make predictions on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to do**</font>: Define a general purpose testing routine that takes as input:\n",
    "* the arrays `pi`, `mu`, `sigma` defining the generative model, as above\n",
    "* the test set (points `tx` and labels `ty`)\n",
    "* a list of features `features` (chosen from 0-12)\n",
    "\n",
    "It should return the number of mistakes made by the generative model on the test data, *when restricted to the specified features*. For instance, using the just three features 2 (`'Ash'`), 4 (`'Magnesium'`) and 6 (`'Flavanoids'`) results in 7 mistakes (out of 48 test points), so \n",
    "\n",
    "        `test_model(mu, sigma, pi, [2,4,6], testx, testy)` \n",
    "\n",
    "should print 7/48.\n",
    "\n",
    "**Hint:** The way you restrict attention to a subset of features is by choosing the corresponding coordinates of the full 13-dimensional mean and the appropriate submatrix of the full 13x13 covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T18:58:49.622285Z",
     "start_time": "2019-03-27T18:58:49.607956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 28/48 cases\n"
     ]
    }
   ],
   "source": [
    "## for whole 3x13x13 matrix\n",
    "\n",
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k = len(set(trainy))\n",
    "score = np.zeros((len(testx),k))\n",
    "\n",
    "for label in range(0,k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0,len(testx)):\n",
    "        score[i,label] = np.log(pi[label]) + rv.logpdf(testx[i,:])\n",
    "\n",
    "predictions = np.add(np.argmax(score, axis=1),1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(np.equal(predictions, testy))\n",
    "print(\"Your model was correct for \" + str(errors) + \"/\" +str(len(testx))+ \" cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T18:59:42.252389Z",
     "start_time": "2019-03-27T18:59:42.239420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 17/48 cases\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "features = [2,4,6]\n",
    "k = len(set(trainy))\n",
    "score = np.zeros((len(testx),k))\n",
    "\n",
    "for label in range(0,k):\n",
    "    mu_filtered = np.asarray(mu[label][features])\n",
    "    sigma_filtered = np.asarray([[sigma[label][v][x] for x in features] for v in features])\n",
    "    testx_filtered = np.asarray(testx[:,[features]])\n",
    "\n",
    "    rv = multivariate_normal(mean=mu_filtered\n",
    "                             , cov=sigma_filtered\n",
    "                            )\n",
    "    for i in range(0,len(testx)):\n",
    "#        testx_filtered = np.asarray([testx[i,f] for f in features])\n",
    "        score[i,label] = np.log(pi[label]) + rv.logpdf(testx_filtered[i,:])\n",
    "\n",
    "predictions = np.add(np.argmax(score, axis=1),1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(np.equal(predictions, testy))\n",
    "print(\"Your model was correct for \" + str(errors) + \"/\" +str(len(testx))+ \" cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:02.378975Z",
     "start_time": "2019-03-27T19:08:02.368433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "def test_model(mu, sigma, pi, features, testx, testy):\n",
    "    ###\n",
    "#    features = [2,4,6]\n",
    "    k = len(set(testy))\n",
    "    score = np.zeros((len(testx),k))\n",
    "\n",
    "    for label in range(0,k):\n",
    "        mu_filtered = np.asarray(mu[label][features])\n",
    "        sigma_filtered = np.asarray([[sigma[label][v][x] for x in features] for v in features])\n",
    "        testx_filtered = np.asarray(testx[:,[features]])\n",
    "\n",
    "        rv = multivariate_normal(mean=mu_filtered\n",
    "                                 , cov=sigma_filtered\n",
    "                                )\n",
    "        for i in range(0,len(testx)):\n",
    "    #        testx_filtered = np.asarray([testx[i,f] for f in features])\n",
    "            score[i,label] = np.log(pi[label]) + rv.logpdf(testx_filtered[i,:])\n",
    "\n",
    "    predictions = np.add(np.argmax(score, axis=1),1)\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(np.equal(predictions, testy))\n",
    "    print(\"Your model was correct for \" + str(errors) + \"/\" +str(len(testx))+ \" cases\")\n",
    "    print(\"it was wrong in {} cases\".format(len(testx)-errors))\n",
    "    return int(errors)\n",
    "    ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercises</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note down the answers to these questions. You will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:07.424730Z",
     "start_time": "2019-03-27T19:08:07.417105Z"
    }
   },
   "outputs": [],
   "source": [
    "mu, sigma, pi = fit_generative_model(trainx,trainy,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1. How many errors are made on the test set when using the single feature 'Ash'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:07.877750Z",
     "start_time": "2019-03-27T19:08:07.863924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 17/48 cases\n",
      "it was wrong in 31 cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [2], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2. How many errors when using 'Alcohol' and 'Ash'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:10.081546Z",
     "start_time": "2019-03-27T19:08:10.066908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 29/48 cases\n",
      "it was wrong in 19 cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [0,2], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3. How many errors when using 'Alcohol', 'Ash', and 'Flavanoids'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:10.929480Z",
     "start_time": "2019-03-27T19:08:10.911017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 45/48 cases\n",
      "it was wrong in 3 cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [0,2,6], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4. How many errors when using all 13 features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:11.662316Z",
     "start_time": "2019-03-27T19:08:11.638973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 47/48 cases\n",
      "it was wrong in 1 cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, range(0,13), testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5. In lecture, we got somewhat different answers to these questions. Why do you think that might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:15.741511Z",
     "start_time": "2019-03-27T19:08:15.737923Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:08:16.195743Z",
     "start_time": "2019-03-27T19:08:15.928962Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 41/48 cases\n",
      "it was wrong in 7 cases\n",
      "Your model was correct for 41/48 cases\n",
      "it was wrong in 7 cases\n",
      "Your model was correct for 38/48 cases\n",
      "it was wrong in 10 cases\n",
      "Your model was correct for 36/48 cases\n",
      "it was wrong in 12 cases\n",
      "Your model was correct for 36/48 cases\n",
      "it was wrong in 12 cases\n",
      "Your model was correct for 34/48 cases\n",
      "it was wrong in 14 cases\n",
      "Your model was correct for 34/48 cases\n",
      "it was wrong in 14 cases\n",
      "Your model was correct for 34/48 cases\n",
      "it was wrong in 14 cases\n",
      "Your model was correct for 33/48 cases\n",
      "it was wrong in 15 cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:00<00:00, 86.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 33/48 cases\n",
      "it was wrong in 15 cases\n",
      "Your model was correct for 33/48 cases\n",
      "it was wrong in 15 cases\n",
      "Your model was correct for 33/48 cases\n",
      "it was wrong in 15 cases\n",
      "Your model was correct for 33/48 cases\n",
      "it was wrong in 15 cases\n",
      "Your model was correct for 32/48 cases\n",
      "it was wrong in 16 cases\n",
      "Your model was correct for 32/48 cases\n",
      "it was wrong in 16 cases\n",
      "Your model was correct for 31/48 cases\n",
      "it was wrong in 17 cases\n",
      "Your model was correct for 30/48 cases\n",
      "it was wrong in 18 cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [00:00<00:00, 82.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model was correct for 30/48 cases\n",
      "it was wrong in 18 cases\n",
      "Your model was correct for 29/48 cases\n",
      "it was wrong in 19 cases\n",
      "Your model was correct for 29/48 cases\n",
      "it was wrong in 19 cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 78.87it/s]\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i in tqdm([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]):\n",
    "    mu, sigma, pi = fit_generative_model(trainx,trainy,i)\n",
    "    res[str(i)] = test_model(mu, sigma, pi, [2,4,6], testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T19:06:46.220626Z",
     "start_time": "2019-03-27T19:06:46.213428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 41,\n",
       " '2': 41,\n",
       " '3': 38,\n",
       " '4': 36,\n",
       " '5': 36,\n",
       " '6': 34,\n",
       " '7': 34,\n",
       " '8': 34,\n",
       " '9': 33,\n",
       " '10': 33,\n",
       " '11': 33,\n",
       " '12': 33,\n",
       " '13': 33,\n",
       " '14': 32,\n",
       " '15': 32,\n",
       " '16': 31,\n",
       " '17': 30,\n",
       " '18': 30,\n",
       " '19': 29,\n",
       " '20': 29}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
